name: Scrape Combined Hotel Rates

on:
  # nightly at 02:00 UTC
  schedule:
    - cron: '0 2 * * *'
  # manual run
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # 1) Checkout the ‘main’ branch explicitly
      - name: Checkout main
        uses: actions/checkout@v3
        with:
          ref: main

      # 2) List everything so we can confirm paths
      - name: Debug: list workspace contents
        run: |
          echo "== PWD: $PWD =="
          ls -R .

      # 3) Set up Python
      - name: Set up Python 3.x
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      # 4) Install requirements
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      # 5) Run the scraper from the repo root
      - name: Run combined scraper
        env:
          SERPAPI_KEY:     ${{ secrets.SERPAPI_KEY }}
          RAPIDAI_API_KEY: ${{ secrets.RAPIDAI_API_KEY }}
        run: |
          python scrape_combined_rates.py
